{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advent of code 2018 day 1-10\n",
    "See https://adventofcode.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this notebook requires the .venv environment (which is set up with pypy3.10-v7.3.13-win64)\n",
    "# to activate it from a git bash shell: source .venv/Scripts/activate\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import functools\n",
    "import re\n",
    "import copy\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import heapq\n",
    "import bisect\n",
    "import random\n",
    "import sortedcontainers\n",
    "\n",
    "import zio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version check and timestamp\n",
    "# NB the timestamp supports ranking using an honor system, before starting include this line\n",
    "# in the header of your solution (which should start with a line like # 2019 day 2), then whenever you want save\n",
    "# a private leaderboard json file, and run python privaterank.py filename.json\n",
    "\n",
    "print(f'python version: {sys.version}')\n",
    "print(f'# start_ts={int(time.time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 day 2\n",
    "# start_ts=1701377203\n",
    "# mv ~/Downloads/input* data_src/2018-day-2-input.txt\n",
    "# big input file looks like: list of strings\n",
    "# idea: part 1 parse as list, then per line / word count letter frequencies, then count words\n",
    "#  which have a letter with a certain frequency, then multiply those two values\n",
    "# part 2: totally unrelated to part 1 (?) generate each pair of words, count different letters in\n",
    "#  the same position, collect common letters, if only one different that's the answer\n",
    "\n",
    "def count_freqs_n(strs, n):\n",
    "    '''return number of strings with a letter that occurs exactly n times'''\n",
    "    cnt=0\n",
    "    for s in strs:\n",
    "        counter=collections.Counter()\n",
    "        for c in s:\n",
    "            counter[c]+=1\n",
    "        for v in counter.values():\n",
    "            if v==n:\n",
    "                cnt+=1\n",
    "                break\n",
    "    return cnt\n",
    "\n",
    "sample1=open('data_src/2018-day-2-input.txt').read()\n",
    "lines=[s for s in sample1.splitlines() if len(s)>0 ]\n",
    "\n",
    "# part 1\n",
    "a=count_freqs_n(lines, 2)\n",
    "b=count_freqs_n(lines, 3)\n",
    "n=a*b\n",
    "print(f'part 1: {n=}')\n",
    "\n",
    "# part 2\n",
    "for i, sa in enumerate(lines):\n",
    "    for sb in lines[:i]:\n",
    "        assert len(sa)==len(sb)\n",
    "        common=''\n",
    "        diffcnt=0\n",
    "        for j in range(len(sa)):\n",
    "            if sa[j]==sb[j]:\n",
    "                common=common+sa[j]\n",
    "            else:\n",
    "                diffcnt+=1\n",
    "        if diffcnt==1:\n",
    "            print(f'part 2: {common=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 day 1\n",
    "# start_ts=1701341821\n",
    "# mv ~/Downloads/input* data_src/2018-day-1-input.txt\n",
    "# big input file looks like: pos. and negative numbers\n",
    "# idea: part 1 parse then add, skipping leading + (wasn't actually needed)\n",
    "# part 2: keep looping, keeping reached frequencies in a set\n",
    "\n",
    "sample1=open('data_src/2018-day-1-input.txt').read()\n",
    "lines=[s for s in sample1.splitlines() if len(s)>0 ]\n",
    "\n",
    "# part 1\n",
    "n=0\n",
    "for s in lines:\n",
    "    if s[0]=='+':\n",
    "        n+=int(s[1:])\n",
    "    else:\n",
    "        n+=int(s)\n",
    "print(f'part 1: {n=}')\n",
    "\n",
    "# part 2\n",
    "n=0\n",
    "seenfreq=set()\n",
    "stopped=False\n",
    "while not stopped:\n",
    "    for s in lines:\n",
    "        if s[0]=='+':\n",
    "            n+=int(s[1:])\n",
    "        else:\n",
    "            n+=int(s)\n",
    "        if n in seenfreq:\n",
    "            stopped=True\n",
    "            break\n",
    "        seenfreq.add(n)\n",
    "print(f'part 2: {n=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPLATE\n",
    "# 2018 day 1\n",
    "# start_ts=RUN FIRST CELL TO GET TIME CODE BEFORE OPENING THE ASSIGNMENT\n",
    "# mv ~/Downloads/input* data_src/2018-day-1-input.txt\n",
    "# big input file looks like: \n",
    "# idea: part 1 parse ..., then ...\n",
    "\n",
    "sample2='''\n",
    "\n",
    "'''\n",
    "\n",
    "sample1=open('data_src/2018-day-1-input.txt').read()\n",
    "lines=[s for s in sample1.splitlines() if len(s)>0 ]\n",
    "groups=zio.get_line_groups(sample1.splitlines(), nostrip=False)\n",
    "data=[ int(s) for s in lines[0].split(',') ]\n",
    "data=[ s.split() for s in lines ]\n",
    "data=[ [cmd, int(num), 0] for cmd, num in data ]\n",
    "data=[ result.group(1, 2, 3, 4, 5, 6, 7) for s in lines if (result:= re.match(r'(\\w+)\\s*x=([\\d\\-]+)\\.\\.([\\d\\-]+),y=([\\d\\-]+)\\.\\.([\\d\\-]+),z=([\\d\\-]+)\\.\\.([\\d\\-]+)', s)) ]\n",
    "data=[ (row[0], int(row[1]), int(row[2]), int(row[3]), int(row[4]), int(row[5]), int(row[6]) ) for row in data ]\n",
    "# template, remove what's not needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv-pypy': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7010e2a1653d53559e0fa20e42ca17494ec8a490802f16a6acb2bec611e573b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
